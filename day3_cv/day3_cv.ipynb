{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e39eb3",
   "metadata": {},
   "source": [
    "# Face anoninymizer project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9858a5a",
   "metadata": {},
   "source": [
    "Process : \n",
    "- read the image\n",
    "- detect the faces\n",
    "- blur the faces\n",
    "- save the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706f5787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import argparse\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b587a",
   "metadata": {},
   "source": [
    "## Building face anonymizer on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce83e30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the image + some basic operations\n",
    "image_path_read = os.path.join('.', \"katniss.jpg\")\n",
    "img = cv2.imread(image_path_read)\n",
    "img = cv2.resize(img, (534, 300))\n",
    "H, W, _ = img.shape\n",
    "print(H, W)\n",
    "\n",
    "# Detect faces\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "# Model selection = 0 : faces close to the camera\n",
    "with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert BRD to RGB\n",
    "    out = face_detection.process(img_rgb)\n",
    "    #print(out.detections)\n",
    "    if out.detections:  # Making sure we have at least one face in the image\n",
    "        for detection in out.detections:\n",
    "            location_data = detection.location_data\n",
    "            bbox = location_data.relative_bounding_box\n",
    "            x1, y1, w, h = bbox.xmin, bbox.ymin, bbox.width, bbox.height\n",
    "            \n",
    "            # Convert the coordinates of the bounding box into an int, as it is a relative bbox\n",
    "            x1 = int(x1*W) \n",
    "            y1 = int(y1*W) \n",
    "            w = int(w*W) \n",
    "            h = int(h*W) # Had to add 50 here cuz for some reason, it wasn't taking the whole face\n",
    "            # 2 next lines needed as idk why, but the whole face isn't taken into consideration\n",
    "            y1 -= 100\n",
    "            h -= 50\n",
    "            #cv2.rectangle(img, (x1, y1), (x1+w, y1+h), (0, 255, 0), 3)\n",
    "            \n",
    "            # Blur faces\n",
    "            img[y1:y1+h, x1:x1+w, :] = cv2.blur(img[y1:y1+h, x1:x1+w, :], (30, 30))\n",
    "\n",
    "            # Display image\n",
    "            # cv2.imshow('frame', img)\n",
    "            # cv2.waitKey(0) \n",
    "            # cv2.destroyAllWindows()\n",
    "            \n",
    "# Save the image : \n",
    "cv2.imwrite(os.path.join('.', \"output.jpg\"), img)            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d0ce1",
   "metadata": {},
   "source": [
    "## Building face anonymizer for video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86b0dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build face anonymizer for video\n",
    "def process_image(img, face_detection):\n",
    "    H, W, _ = img.shape\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    out = face_detection.process(img_rgb)\n",
    "\n",
    "    if out.detections:  \n",
    "        for detection in out.detections:\n",
    "            location_data = detection.location_data\n",
    "            bbox = location_data.relative_bounding_box\n",
    "            x1, y1, w, h = bbox.xmin, bbox.ymin, bbox.width, bbox.height\n",
    "            \n",
    "            # Convert the coordinates of the bounding box into an int, as it is a relative bbox\n",
    "            x1 = int(x1*W) \n",
    "            y1 = int(y1*H) \n",
    "            w = int(w*W) \n",
    "            h = int(h*H) \n",
    "            \n",
    "            # Not needed for all the images/vids\n",
    "            # y1 -= 100\n",
    "            # h -= 50\n",
    "            \n",
    "            # Blur faces\n",
    "            img[y1:y1+h, x1:x1+w, :] = cv2.blur(img[y1:y1+h, x1:x1+w, :], (30, 30))\n",
    "            \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a70b578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = os.path.join('.', \"katniss.jpg\")\n",
    "video_path = os.path.join('.', \"my_vid.mp4\")\n",
    "desired_mode = 'video'\n",
    "\n",
    "args = argparse.ArgumentParser()\n",
    "args.add_argument(\"--mode\", default=desired_mode) # Mode = mode selection depending on what the user wants to anonymate the faces on (video, webcam, image)\n",
    "args.add_argument(\"--filePath\", default=video_path)\n",
    "args = args.parse_args(['--filePath', video_path]) #'--mode', desired_mode,\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "    if args.mode in [\"image\"]:\n",
    "        # Read image\n",
    "        img = cv2.imread(args.filePath)\n",
    "        img = cv2.resize(img, (534, 300))\n",
    "        img = process_image(img, face_detection)\n",
    "        cv2.imwrite(os.path.join('.', \"output_img.jpg\"), img)     \n",
    "    \n",
    "    elif args.mode in [\"video\"]:\n",
    "        vid = cv2.VideoCapture(args.filePath)\n",
    "        ret, frame = vid.read()\n",
    "        output_video = cv2.VideoWriter(os.path.join(\".\", 'output_vid.mp4'),\n",
    "                                       cv2.VideoWriter_fourcc(*'MP4V'),\n",
    "                                       25,\n",
    "                                       (frame.shape[1], frame.shape[0]))\n",
    "        \n",
    "        while ret:\n",
    "            frame = process_image(frame, face_detection)\n",
    "            output_video.write(frame)\n",
    "            ret, frame = vid.read()\n",
    "        \n",
    "            \n",
    "        vid.release()  \n",
    "        output_video.release()\n",
    "        \n",
    "    elif args.mode in [\"webcam\"]:\n",
    "        cam = cv2.VideoCapture(0)\n",
    "        ret, frame = cam.read()\n",
    "        \n",
    "        while ret:\n",
    "            frame = process_image(frame, face_detection)\n",
    "            cv2.imshow(\"frame\", frame)\n",
    "            cv2.waitKey(25)\n",
    "            ret, frame = cam.read()\n",
    "        cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a76d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5dc7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d41ce10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811f738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61ab1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759a153c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfa375d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0db14288",
   "metadata": {},
   "source": [
    "## Previous tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For another image\n",
    "image_path_read = os.path.join('.', \"image.jpg\")\n",
    "img = cv2.imread(image_path_read)\n",
    "img = cv2.resize(img, (414, 736))\n",
    "img = img[175:730, 0:414] # Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea856743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read image from: .\\katniss.jpg\n",
      "Image loaded successfully. Shape: (900, 1600, 3)\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join('.', \"katniss.jpg\")\n",
    "args = argparse.ArgumentParser()\n",
    "args.add_argument(\"--mode\", default='image') # Mode = mode selection depending on what the user wants to anonymate the faces on (video, webcam, image)\n",
    "args.add_argument(\"--filePath\", default=file_path)\n",
    "args = args.parse_args(['--filePath', file_path])\n",
    "\n",
    "print(f\"Attempting to read image from: {args.filePath}\")\n",
    "\n",
    "img = cv2.imread(args.filePath)\n",
    "\n",
    "if img is None:\n",
    "    print(f\"Error: cv2.imread() returned None. Could not load image from {args.filePath}\")\n",
    "else:\n",
    "    print(f\"Image loaded successfully. Shape: {img.shape}\")\n",
    "    cv2.imshow('frame', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
